{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from quaternion import from_rotation_matrix, quaternion\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from rlbench.environment import Environment\n",
    "from rlbench.action_modes import ArmActionMode, ActionMode\n",
    "from rlbench.observation_config import ObservationConfig, CameraConfig\n",
    "from rlbench.tasks import PutGroceriesInCupboard\n",
    "from pyrep.const import ConfigurationPathAlgorithms as Algos\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "import copy\n",
    "\n",
    "from utils import RandomAgent, NoisyObjectPoseSensor, VisionObjectPoseSensor, RobotController\n",
    "\n",
    "from autolab_core import RigidTransform, YamlConfig, Logger\n",
    "from perception import RgbdImage, RgbdSensorFactory, Image, CameraIntrinsics, DepthImage\n",
    "\n",
    "from visualization import Visualizer2D as vis\n",
    "\n",
    "from gqcnn.grasping import AntipodalDepthImageGraspSampler, RgbdImageState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gqcnn.grasping import (RobustGraspingPolicy,\n",
    "                            CrossEntropyRobustGraspingPolicy, RgbdImageState,\n",
    "                            FullyConvolutionalGraspingPolicyParallelJaw,\n",
    "                            FullyConvolutionalGraspingPolicySuction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set Action Mode\n",
    "action_mode = ActionMode(ArmActionMode.ABS_JOINT_POSITION) # See rlbench/action_modes.py for other action modes\n",
    "\n",
    "### Creating cameras and observation models\n",
    "wrist_camera_config = CameraConfig()\n",
    "wrist_camera_config.image_size=(1032,722)\n",
    "\n",
    "other_camera_config = CameraConfig()\n",
    "other_camera_config.rgb = False\n",
    "other_camera_config.depth = False\n",
    "other_camera_config.mask = False\n",
    "\n",
    "obs_config = ObservationConfig()\n",
    "obs_config.left_shoulder_camera = other_camera_config\n",
    "obs_config.right_shoulder_camera = other_camera_config\n",
    "obs_config.front_camera = other_camera_config\n",
    "obs_config.wrist_camera = wrist_camera_config\n",
    "\n",
    "\n",
    "### Initialize Environment with Action Mode and desired observations\n",
    "env = Environment(action_mode, '', obs_config, False, static_positions=True)\n",
    "\n",
    "### Load task into the environment\n",
    "task = env.get_task(PutGroceriesInCupboard)\n",
    "\n",
    "### Create Agent: TODO\n",
    "agent = RandomAgent()\n",
    "\n",
    "### Object Pose Sensor\n",
    "obj_pose_sensor = NoisyObjectPoseSensor(env)\n",
    "\n",
    "### Robot Controller Object\n",
    "robot_controller = RobotController(env, task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = \"/home/mayank/Mayank/Autonomy/project/CerealGrabber/antipodal_grasp_sampling.yaml\"\n",
    "config = YamlConfig(config_filename)\n",
    "\n",
    "\n",
    "num_grasp_samples = 500\n",
    "gripper_width = 0.08\n",
    "visualize_sampling = config[\"policy\"][\"vis\"]\n",
    "sample_config = config[\"policy\"][\"sampling\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Useful variables\n",
    "gripper_vertical_orientation = np.array([3.13767052e+00, 1.88300957e-03, 9.35417891e-01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions, obs = task.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Motion 1\n",
    "## (1) Sense mustard_grasp_point location. (2) Move gripper to a point 0.1m over mustard_grasp_point, while making it remain vertical.\n",
    "\n",
    "#(1)\n",
    "next_position, next_orientation, crackers_obj = robot_controller.get_pose_and_object_from_simulation(\"crackers_grasp_point\")\n",
    "\n",
    "#(2)\n",
    "next_position[2] += 0.2\n",
    "next_orientation = gripper_vertical_orientation\n",
    "motion_1_plan, obs = robot_controller.move(next_position, next_orientation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, obs = robot_controller.translate(z=+0.2, ignore_collisions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "color_im = Image(obs.wrist_rgb*255, frame='camera')\n",
    "depth_im = DepthImage(obs.wrist_depth, frame='camera')\n",
    "rgbd_im = RgbdImage.from_color_and_depth(color_im, depth_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_im._data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasp_sampler = AntipodalDepthImageGraspSampler(sample_config,\n",
    "                                                gripper_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_x = 722/2\n",
    "center_y = 1032/2\n",
    "fy = center_y / np.tan(60/2)\n",
    "fx = fy\n",
    "\n",
    "camera_intr = CameraIntrinsics(fx=fx, fy=fy, cx=center_x, cy=center_y, frame='camera', height=1032, width=722)\n",
    "\n",
    "# center_x = 1032/2\n",
    "# center_y = 722/2\n",
    "# fx = center_x / np.tan(60/2)\n",
    "# fy = fx\n",
    "\n",
    "# camera_intr = CameraIntrinsics(fx=fx, fy=fy, cx=center_x, cy=center_y, frame='camera', height=722, width=1032)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grasps = grasp_sampler.sample(rgbd_im,\n",
    "                              camera_intr,\n",
    "                              num_grasp_samples,\n",
    "                              segmask=None,\n",
    "                              seed=50,\n",
    "                              visualize=visualize_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize.\n",
    "vis.figure()\n",
    "vis.imshow(depth_im)\n",
    "for grasp in grasps:\n",
    "    vis.grasp(grasp, scale=1.5, show_center=False, show_axis=True)\n",
    "vis.title(\"Sampled grasps\")\n",
    "vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_px_mask = depth_im.invalid_pixel_mask().inverse()\n",
    "segmask = valid_px_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = RgbdImageState(rgbd_im, camera_intr, segmask=segmask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input sizes for fully-convolutional policy.\n",
    "\n",
    "\n",
    "fully_conv = True\n",
    "\n",
    "policy_config = YamlConfig(\"/home/mayank/Mayank/Autonomy/project/CerealGrabber/policy.yaml\")[\"policy\"]\n",
    "\n",
    "if fully_conv:\n",
    "    policy_config[\"metric\"][\"fully_conv_gqcnn_config\"][\n",
    "        \"im_height\"] = depth_im.shape[0]\n",
    "    policy_config[\"metric\"][\"fully_conv_gqcnn_config\"][\n",
    "        \"im_width\"] = depth_im.shape[1]\n",
    "\n",
    "# Init policy.\n",
    "if fully_conv:\n",
    "    # TODO(vsatish): We should really be doing this in some factory policy.\n",
    "    if policy_config[\"type\"] == \"fully_conv_suction\":\n",
    "        policy = FullyConvolutionalGraspingPolicySuction(policy_config)\n",
    "    elif policy_config[\"type\"] == \"fully_conv_pj\":\n",
    "        policy = FullyConvolutionalGraspingPolicyParallelJaw(policy_config)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid fully-convolutional policy type: {}\".format(\n",
    "                policy_config[\"type\"]))\n",
    "else:\n",
    "    policy_type = \"cem\"\n",
    "    if \"type\" in policy_config:\n",
    "        policy_type = policy_config[\"type\"]\n",
    "    if policy_type == \"ranking\":\n",
    "        policy = RobustGraspingPolicy(policy_config)\n",
    "    elif policy_type == \"cem\":\n",
    "        policy = CrossEntropyRobustGraspingPolicy(policy_config)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid policy type: {}\".format(policy_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query policy.\n",
    "policy_start = time.time()\n",
    "action = policy(state)\n",
    "\n",
    "# Vis final grasp.\n",
    "if policy_config[\"vis\"][\"final_grasp\"]:\n",
    "    vis.figure(size=(10, 10))\n",
    "    vis.imshow(rgbd_im.depth,\n",
    "               vmin=policy_config[\"vis\"][\"vmin\"],\n",
    "               vmax=policy_config[\"vis\"][\"vmax\"])\n",
    "    vis.grasp(action.grasp, scale=2.5, show_center=False, show_axis=True)\n",
    "    vis.title(\"Planned grasp at depth {0:.3f}m with Q={1:.3f}\".format(\n",
    "        action.grasp.depth, action.q_value))\n",
    "    vis.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
